{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying EMD to de-trend historical consumption\n",
    "EMD (empirical mode decomposition) is an algorithm to decompose a time serie into intrisic mode functions (IMFs). The EMD algorithm is also called Hilbert-Huang transform, and is robust to non stationary and non linear time series. Original paper : https://royalsocietypublishing.org/doi/10.1098/rspa.1998.0193"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the folder where the data lives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:\\\\Users\\\\chris\\\\Documents\\\\GitHub\\\\data\\\\f28e28af-5e8b-44e4-bf01-e85eb1c221fb\\\\f28e28af-5e8b-44e4-bf01-e85eb1c221fb\\\\load'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the files living in the data folder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(data_dir) if isfile(join(data_dir, f))]\n",
    "print(onlyfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime,timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read two random files from the dataset\n",
    "Read the dates using the data parser, and transforming to UTC (needed as +01 and +02 co-exist in the same file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.randint(0,len(onlyfiles),2)\n",
    "pd1 = pd.read_csv(join(data_dir,onlyfiles[rnd[0]]),sep=';',parse_dates=[0],date_parser=lambda col: pd.to_datetime(col, utc=True))\n",
    "pd2 = pd.read_csv(join(data_dir,onlyfiles[rnd[1]]),sep=';',parse_dates=[0],date_parser=lambda col: pd.to_datetime(col, utc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' -- Analyzing {onlyfiles[rnd[0]]} as first example')\n",
    "print(f' -- Analyzing {onlyfiles[rnd[1]]} as second example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check types\n",
    "pd1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first four rows\n",
    "pd1.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the dates as index and fix the summer winter stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1=pd1.set_index('date_tz')\n",
    "pd2=pd2.set_index('date_tz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing the double hour (from summer to winter)\n",
    "pd1[pd1.index==datetime(2017,10,29,2,0,0,tzinfo=timezone.utc)]=pd1[pd1.index==datetime(2017,10,29,2,0,0,tzinfo=timezone.utc)]/2\n",
    "pd1[pd1.index==datetime(2018,10,28,2,0,0,tzinfo=timezone.utc)]=pd1[pd1.index==datetime(2018,10,28,2,0,0,tzinfo=timezone.utc)]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated hours (from winter to summer)\n",
    "pd1 = pd1[~pd1.index.duplicated()]\n",
    "pd2 = pd2[~pd2.index.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First de-trending : remove the average over the whole period\n",
    "Not sure this step is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = pd1['kWh/h'].mean()\n",
    "m2 = pd2['kWh/h'].mean()\n",
    "pd1['kWh/h'] = pd1['kWh/h']-m1\n",
    "pd2['kWh/h'] = pd2['kWh/h']-m2\n",
    "print(f' -- Removed a constant of {m1:0.2f} kWh/h from the first example')\n",
    "print(f' -- Removed a constant of {m2:0.2f} kWh/h from the first example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1.plot(figsize=[8,8])\n",
    "pd2.plot(figsize=[8,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Resample the hourly curves into weekly curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1_rs = pd1.resample(rule='W',axis=0).mean()\n",
    "pd2_rs = pd2.resample(rule='W',axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1_rs.plot(figsize=[8,8])\n",
    "pd2_rs.plot(figsize=[8,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the seasonal trend using EMD on the sub sampled weekly timeseries\n",
    "Should test EEMD as well, but more computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyEMD import EMD,Visualisation\n",
    "emd1 = EMD()\n",
    "emd2 = EMD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the IMFs with, 10 iterations per IMFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd1.FIXE = 10\n",
    "imfs1 = emd1(pd1_rs['kWh/h'])\n",
    "emd2.FIXE = 10\n",
    "imfs2 = emd2(pd2_rs['kWh/h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=Visualisation()\n",
    "v1.plot_imfs(imfs=imfs1,include_residue=False)\n",
    "v2=Visualisation()\n",
    "v2.plot_imfs(imfs=imfs2,include_residue=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the seasonal trends are captured. The difficulty with EMD is to decide (programatically) which are the IMFs which embed the seasonal info (four seasons), and which are the ones with higher frequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the IMFs in a Dataframe and merge with the sub sampled load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imfs1_pd=pd.DataFrame.from_records(np.transpose(imfs1),index=pd1_rs.index,columns=[f'imf{n}' for n in range(0,imfs1.shape[0])])\n",
    "imfs2_pd=pd.DataFrame.from_records(np.transpose(imfs2),index=pd2_rs.index,columns=[f'imf{n}' for n in range(0,imfs2.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1_new = pd1_rs.merge(right=imfs1_pd,left_index=True,right_index=True)\n",
    "pd2_new = pd2_rs.merge(right=imfs2_pd,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1_new.plot(figsize=[8,8])\n",
    "pd2_new.plot(figsize=[8,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsample the IMFs to hourly frequence\n",
    "Linear interpolation is more than OK here, no need to complicate things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imfs1_pd_hr = imfs1_pd.resample(rule='H',axis=0).interpolate(method='linear')\n",
    "imfs2_pd_hr = imfs2_pd.resample(rule='H',axis=0).interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge with the original timeserie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1=pd1.merge(right=imfs1_pd_hr,left_index=True,right_index=True)\n",
    "pd2=pd2.merge(right=imfs2_pd_hr,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1.plot(figsize=[8,8])\n",
    "pd2.plot(figsize=[8,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the de-trending by removing the 3 first IMFs from the timeserie\n",
    "The number three is completly experimental, and might not fit certain timeseries that have few IMFs. A bit smarter approach (could be as simple as if len(IMF)==3, use one, if len(IMF)==5, use two, etc...) should be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1['detrend']=pd1['kWh/h']-(pd1[f'imf{imfs1.shape[0]-1}']+pd1[f'imf{imfs1.shape[0]-2}']+pd1[f'imf{imfs1.shape[0]-3}'])\n",
    "pd2['detrend']=pd2['kWh/h']-(pd2[f'imf{imfs2.shape[0]-1}']+pd2[f'imf{imfs2.shape[0]-2}']+pd2[f'imf{imfs2.shape[0]-3}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1.plot(figsize=[12,8])\n",
    "pd2.plot(figsize=[12,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final standardisation : put all the values between zero and one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1['detrend_norm']=(pd1['detrend']-pd1['detrend'].min())/(pd1['detrend'].max()-pd1['detrend'].min())\n",
    "pd2['detrend_norm']=(pd2['detrend']-pd2['detrend'].min())/(pd2['detrend'].max()-pd2['detrend'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1['detrend_norm'].plot(figsize=[12,8])\n",
    "pd2['detrend_norm'].plot(figsize=[12,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Plotly for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=pd1.index, y=pd1['detrend_norm'], name=\"Detrend Norm 1\",\n",
    "                         line_color='deepskyblue'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=pd2.index, y=pd2['detrend_norm'], name=\"Detrend Norm 2\",\n",
    "                         line_color='dimgray'))\n",
    "\n",
    "fig.update_layout(title_text='Detrend with Rangeslider',\n",
    "                  xaxis_rangeslider_visible=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting looking at some trends\n",
    "Here I look at the average for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[16,8])\n",
    "for d in range(0,7):\n",
    "    test_pd = pd1.loc[pd1.index.dayofweek==d,'detrend_norm']\n",
    "    mean_cons=[]\n",
    "    for f in range(0,24):\n",
    "        mean_cons.append(test_pd.loc[(test_pd.index.hour==f)].mean())\n",
    "    plt.plot(range(0,24),mean_cons)\n",
    "\n",
    "fig2 = plt.figure(figsize=[16,8])\n",
    "for d in range(0,7):\n",
    "    test_pd = pd2.loc[pd2.index.dayofweek==d,'detrend_norm']\n",
    "    mean_cons=[]\n",
    "    for f in range(0,24):\n",
    "        mean_cons.append(test_pd.loc[(test_pd.index.hour==f)].mean())\n",
    "    plt.plot(range(0,24),mean_cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
